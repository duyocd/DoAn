{"class":"org.apache.spark.ml.feature.Tokenizer","timestamp":1747319091011,"sparkVersion":"3.5.3","uid":"Tokenizer_a94c2df8428c","paramMap":{"inputCol":"Text","outputCol":"tokens"},"defaultParamMap":{"outputCol":"Tokenizer_a94c2df8428c__output"}}
